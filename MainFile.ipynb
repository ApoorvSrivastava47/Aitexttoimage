{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufbkcme55nMb"
   },
   "source": [
    "# Project : Text To AI Image Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WshfsRgbvyPr"
   },
   "source": [
    "**AI Image Generator with Stable Diffusion**\n",
    "\n",
    "\n",
    "This is a simple and powerful AI image generation web app built using Hugging Face's diffusers library and deployed on Gradio + Hugging Face Spaces.\n",
    "\n",
    "It uses **Stable Diffusion v1.5** to generate* high-quality images *from text prompts given by the user.\n",
    "\n",
    "-------------------------------------------------------------------------\n",
    "\n",
    " **Features**\n",
    "\n",
    " Text-to-Image generation using Stable Diffusion\n",
    "\n",
    " Clean and simple web interface via Gradio\n",
    "\n",
    " Fast image generation with GPU support (CUDA)\n",
    "\n",
    " Fully deployable and shareable via Hugging Face Spaces\n",
    "\n",
    " ------------------------------------------------------------------------\n",
    "\n",
    " **Demo**\n",
    "\n",
    " Try it here: https://<your-space-name>.huggingface.space\n",
    "(Replace with your actual Hugging Face Space URL)\n",
    "\n",
    " How It Works\n",
    "User enters a text prompt (e.g., \"a cat sitting on the moon\").\n",
    "\n",
    "The backend runs Stable Diffusion to convert text into an image.\n",
    "\n",
    "The output image is displayed on the web interface in seconds.\n",
    "\n",
    " Requirements\n",
    "These packages are required (also saved in requirements.txt):\n",
    "\n",
    "\n",
    "1.   Txt\n",
    "2.   Copy\n",
    "3.   Edit\n",
    "4.   Diffusers\n",
    "5.   Transformers\n",
    "6.   Accelerate\n",
    "7.   Safetensors\n",
    "8.   Torch\n",
    "9.   Gradio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvuJgxcT0ceK"
   },
   "source": [
    "\n",
    "\n",
    "-------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsTvrbZst1E6"
   },
   "source": [
    "# **Step 1:** Installed and upgraded key HuggingFace libraries italicized text upgraded key HuggingFace libraries\n",
    "\n",
    "\n",
    "1.  Diffusers\n",
    "2.  Transformers\n",
    "\n",
    "Transformers\n",
    "Accelerate\n",
    "Safetensors -to enable use of text generation, text-to-image generation, and fast model execution with secure and efficient model weight loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yHBED87ABzu8",
    "outputId": "73fb1bf0-51d2-43a7-dbbe-9e350c9eebcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.25.0)\n",
      "Collecting diffusers\n",
      "  Downloading diffusers-0.34.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.54.1-py3-none-any.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
      "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.34.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.5.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers) (11.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (1.1.5)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers) (3.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2025.7.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Downloading diffusers-0.34.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.54.1-py3-none-any.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m128.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: diffusers, transformers\n",
      "  Attempting uninstall: diffusers\n",
      "    Found existing installation: diffusers 0.25.0\n",
      "    Uninstalling diffusers-0.25.0:\n",
      "      Successfully uninstalled diffusers-0.25.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.54.0\n",
      "    Uninstalling transformers-4.54.0:\n",
      "      Successfully uninstalled transformers-4.54.0\n",
      "Successfully installed diffusers-0.34.0 transformers-4.54.1\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.5.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers==0.25.0 transformers accelerate gradio --quiet\n",
    "!pip install diffusers transformers accelerate --upgrade\n",
    "!pip install safetensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTiP1pFEGJCe"
   },
   "source": [
    "----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSFaiDRP00Fa"
   },
   "source": [
    "\n",
    "# **Step 2:** Load the Pretrained Model\n",
    "\n",
    "*   Used StableDiffusionPipeline from diffusers:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b46vOtysCSqn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQoYjtogGPyl"
   },
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DC6kvm51OZj"
   },
   "source": [
    "\n",
    "# **Step 3:** Login to Hugging Face\n",
    "\n",
    "*  Used a token to authenticate access to models:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q72XjYIXCeuz"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"YOUR TOKEN HERE\")  # Paste your token here"

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obmLwpoTGUn-"
   },
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRsXBWn01dHb"
   },
   "source": [
    "# **Step 4**: Generate Image from Prompt\n",
    "\n",
    "*   User inputs a text prompt, and the model generates an image\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665,
     "referenced_widgets": [
      "9aa7ebabf43e4b85aa7f1b3e39ab2787",
      "cb1a792d0f4c430da113e50180d45d96",
      "53e7d557373c44a2bb69b6e87614babc",
      "2073e200fa7e49f98ecf341586598135",
      "1900a318ff7d42d9b377df981d451801",
      "feff926e47914fa2a4bc5eb0b187b77b",
      "b34cdd6d0f6b4d23893bf471d9df78e2",
      "d68fa3dd920b4f2980c5ce59dc54185c",
      "1528edc764bf4441b73bde8134bf0bc9",
      "df42354ea74444c1977df5c3b65ad7e0",
      "091a2ae969204272b7c1885dd1f9b124",
      "ff21adac7d6d44f5adfdf7d9b98ab23d",
      "2400060be6234b8a8c800fd2052fa991",
      "1311fe959d624769bb4c518e6178b0d4",
      "29ed0c466fe84cc38490cad1c4dff2f9",
      "3ed810deda3f4367ac632750956afe07",
      "263787087b32449495232eb0d1baa9ee",
      "cec6f030c7b9448daa3a1e07d8bc358c",
      "75951579cde548bf836bbce62ac3d34d",
      "d4d4a1d233c449bdb9ee856652d753a9",
      "c6943d8623274969bd4c7fa904d36f90",
      "3d0dadb6677548eaa35f2e08a1fa263a",
      "790b73e7e4914cf4983248564d7be368",
      "4893127a65bf4581aa39df87ef660705",
      "90a660cdef6049a2abcbc9a675c27ec6",
      "d1cd8fd445584c259b403d616e6e0920",
      "9a8965fd91734960b615c9c0efa2cdfa",
      "23b42b008b404cf5baff962091e9e3c5",
      "53e2ec93bb484dbb9a49288404bcbe4b",
      "856e818b737a4d33a8cd90a42ab8d62b",
      "f77a9578c48a442aa97a8e530f5a3637",
      "7853a8da0313483281b2f50f10a05130",
      "71d8945fcaff442cb3141ab72c4e2e95",
      "f236db1604154688aec89bc9acb8362b",
      "afa06b7e5aaa47a3b710583e1e7cf27c",
      "9dcca514f1214534b421e9a1534b23d6",
      "fe754cdf53da416992ff93e369b9d1cf",
      "2caefbed6ee6431fab846f689495810c",
      "c399c7ed5ca94f5db14cd1d631f6d42a",
      "fa63911e77774f2aa89fd09941a851c8",
      "7d9d4e65562644d4bb2a4828f9c8efc4",
      "42b9d6501a2a4e41bceab03f4d8cfe3f",
      "a455d08ef787443cab09a91415208e56",
      "a8f81aba0ba24e29b05a6f66ac992456",
      "477426adaa064af198aec6f027cda69a",
      "13ac3947e70a4afb8dd50b7f7bd8af4a",
      "e7cca9e51b7e47e99e71e688c2790df8",
      "ab47f7901e634acc8256b9bb7ff2bd2a",
      "bc0fa0b9bef54c5e88bd3e03b676a2b4",
      "d9f3c3942f414dffb6b98065347f01e2",
      "8023260d49a741148df9cc9dd08388a7",
      "6d74f867428947c58680f3f8a4c78c18",
      "e2b44845817a460db26b358dbb8f09f6",
      "d04756c710844f9d891af0d0d7ed8fb3",
      "583918cb80ec4e1aa96f39638a6a3153",
      "6ddf3f66038b47ab8c2e692134cee907",
      "6f48886eb6314539892639695f21205a",
      "ddf67adde3b74e3f9b4dd9cd88d56ab0",
      "8179073f8a9b41d8b3afa95a7a19fe15",
      "dc946070a196470895cf310172fb2529",
      "23282073dc2a49b689d7a4149c9afd8b",
      "23ae045fe7c343d98cf4cf884ded6f7b",
      "e7068cd7253c4b8194bbfa006d382061",
      "3163b471dc9546a0b0d5b4da4a2a731c",
      "4d45da88a6214ebc859f73da49b7e983",
      "3c19a62ffbcf468aa503b44ae6c4d7f0",
      "3b239a1e37084be6b40719719bd35566",
      "5093635abee64152a19c7fcb1713c537",
      "b557edba28ce4d2896d8ef0b8172c6f9",
      "6b66abfb0ad2423cb198f6a21914ac84",
      "8ac80c224965421fbc2ee7fe778d0c01",
      "0345fbe0140a4208b18a8a61001efc09",
      "6a03785774254663a6f9825ff38901a0",
      "9bb9cd53c4224a8989564fc4357e7f4b",
      "5c7d969ad0be4d3fae159fc52178bdea",
      "1d85e84e51f34addbd373259eb361bad",
      "145c5ac18c5241dcafce273e635a2833",
      "3859d5bfea3b42cc8b38780e809038a7",
      "315aac0cb528404cb6b718a3dd0151fb",
      "93325dfd68e545e2b27d532b787ae2cc",
      "bf8064a41f444f3a95977fb06ea85a49",
      "cb7bf0269ecd4b7795c21ed5f431eaba",
      "e1e88ae8677b46e789423283173b502c",
      "054138d1aac74552ad7bcb8a87c98f9c",
      "1594dbdcc9614477a10931ffe2625006",
      "4cb8c37c9d8141c089e6169c25893b85",
      "b5600156b69049828865df6a1c436aac",
      "dbd4c8d868b14d06b0e9363f68bec56c",
      "af737aabed5b4a6c9f8f2df45f0c97e1",
      "ed938cdc448a4c769e3af84492b3cba6",
      "e374f064276240b3b83b37ae71027360",
      "10022d4527704f5fbc99975e85db3157",
      "6f039cef1b0d45cf8436217f06eee4db",
      "ea7bda7d216b4656abfdaa270eac736f",
      "64e06ae449c949bbb36f9ad9848277e0",
      "97d8396b7e13496e9caf654566c1a000",
      "39ad818de8214e79b6a8e93d0c48511b",
      "fb0feb6fc3e044eda5616e964d990143",
      "49baa6b1e635408e8376d77d464d3113",
      "46d13d897c364ca8a9215465bdfe76b9",
      "4e89b5252f954eadb2caef42fe065562",
      "02810b57f752470797860b0cadbde9fc",
      "b4ad9645332147c9ba81cfd1e92e2845",
      "3ea6285807484685a19454d7a1f048fc",
      "e6e8d613525a49bbb11131416460221b",
      "bf446bdc4f5945d0a6a6208a5b9364c0",
      "dab8c7215c844e7fb71c9b87dcabf66c",
      "7cb008c6275443fbb2ed825f87e91d8d",
      "c2b9d3931d5945549f1ef8b1c4bc809c",
      "0ba5b3c1f8ea471bae71eaf9b5d5fbfa",
      "3781bdb455404abd96a3f14e5db96d54",
      "3866d389d25f433c80ce282d584c9c81",
      "59358e2e25c64430b3e57cf5273666dd",
      "1e1c49d4547d4cff8b314645d6f25b42",
      "144acdcd4d2d4220b72c6d20f19c93f1",
      "596a3ce2a30d46fab6f0e9d90015fcad",
      "0bcac6c2cebf4c35b3385741fd0ca106",
      "48935b96fbd541c988f258c12af69ad3",
      "39b6e7d1819e4e7b88310646f32defef",
      "31b541745a984a07b8f3c5fdc06da6c5",
      "caaedd99e0e246df98418dac84b60e5f",
      "15b73e870a764535b5babbbdbe091acb",
      "d9cf3e452bf442c08f791d846036f49e",
      "095cfceecb304192bd1886e12febf952",
      "6b0c82ef86654562b77b2c9c6eefb067",
      "325b58f9a0bf4943828fe3252880ad72",
      "177a53ae3d7b4f599facab953649c605",
      "82cd5dcc7eb1482facb17eebb1283907",
      "a911ddbd70b8449e8db02a5383725184",
      "edbe1dc03dc74f0382425e2867c1931a",
      "689f36b0f1d542c68cda8a9fe86d35e8",
      "2e3e0b26ed4c4fba8dd8cc6956a67f99",
      "f26f270fa3a24bc0bbbf011c726a5aac",
      "1460114b625249e88a1e68055e7ce581",
      "34484a1308fc416db245553eda1ce7fd",
      "eb00c154f4904231a0166a379df3eeec",
      "e6beaabeb1ee44f8bda885e0e294acb4",
      "dfafbe553f9040b48851dd0cd399912f",
      "870a1d08920a4bc2b7751255a99cd164",
      "17d04f90c04747869d556dc8ca2ae159",
      "333123b1d5f5471aa97dd73d26698e1a",
      "38b58bd163284d7cbf73e417320a9761",
      "2dfbe14e65784df8b8a7364474c70874",
      "71799e1b00374a2e95a5a3a11d36b90e",
      "1e8975ca17f14ac49daceacee6d38ae6",
      "836ff28a41e74917b9728368341c61b0",
      "8f66338497754114958b0fffa484d538",
      "7d18bd1bf1474431b00dce42884e7259",
      "c11d0effba374c638c2aa18fb6b65cab",
      "cd7443dc36964c2f92d545a314f86ec0",
      "b33af945405549bc9143abf13fe7cdf0",
      "8bd6952524254aa79a6625bb3532c26d",
      "c9825a7125514b6b9ff179b4978253ec",
      "58200aef27ab4b78ba4e96c4fb4ae6cb",
      "1e9dc035f8f64cc58e379c5bb213b6cf",
      "2e4925adbf804d0c87872450ee3ff3ec",
      "da8f00db09774f4a881c608238dc3fae",
      "f16d516838cb46c487c388802890ed73",
      "2e105cb57a2040df905da026c56e7ffb",
      "90092eec471d4ec0b952404f1903791f",
      "0bfddf20c539454aa75d1fe704fb9ed8",
      "f998f74242fe444d9a7a231f89387da9",
      "c323e83560b74dd385943dac2ba1c28f",
      "dd06201a04f94c7c974341ff3c17f8f3",
      "37f56cdb8fdc492585894ec798a934c3",
      "3f08407fcdde496d987099b2fcde2e37",
      "7105f4a1c2804528ab4179c35f1c03c2",
      "489c311e1b9146bdad89723606222dbc",
      "8ada1ad01a6b4d4bb180b3ca86b1bc59",
      "9eaf360608ea4f2db5d56047f73090f9",
      "4fda5f5a496542d5886c45dfa4615449",
      "575b972c6efc4d65b3ae6790bc056ee7",
      "99208dd9d7604adcba17837441cbe743",
      "14123cc88cd54bfc886f0a97e278b718",
      "b70b38574b7a47ceab9e96b83e504813",
      "a6489f5abb3940c687328da7cd068f58",
      "3de4f6df3611433c8becfde184e2119e",
      "52a7af364be74a228b8abd8b87158784",
      "e76f6c70e91443ffa3dcea0266836b74",
      "0224c1351b8648aea5a588726a19146b",
      "e95611f20747473199c2cc4bb5876ebd",
      "216105ae64914b808de6cabddb4d83ef",
      "89f583d6d9a6466fa2f2036ecd8515c1",
      "14afe828ae1f4ff0b68d2d645b535595",
      "270ea15483744d6b9b4576bdd9686380",
      "39685f9d21484223b5f88b1880e1422a",
      "447f431c3b02407495f95ad59f9d7e40"
     ]
    },
    "id": "rAu1JzAlCmWS",
    "outputId": "f1590b94-46c0-41ef-e7f1-47af62a0bde8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73fad18c581748adaa98fc7662184b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n"
     ]
    }
   ],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True\n",
    ")\n",
    "pipe = pipe.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhZWR_FoGWnl"
   },
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_btHClz1qcz"
   },
   "source": [
    "#   Step 6: Deploying an Interactive Web Interface Using Gradio\n",
    "In this step, we utilize Gradio to create an interactive web-based interface for the text-to-image generation model.\n",
    "\n",
    "* Users can input a descriptive text prompt into the interface.\n",
    "\n",
    "* The pre-trained Stable Diffusion pipeline (pipe) processes the prompt and generates a corresponding image.\n",
    "\n",
    "* The generated image is then displayed directly within the interface.\n",
    "\n",
    "* The launch(share=True) parameter enables access to a publicly shareable URL for demonstration or deployment purposes.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vJtrOhv_CyPc"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def generate_image(prompt):\n",
    "    image = pipe(prompt).images[0]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmdP7EZuGYOd"
   },
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTvvFHty2HmL"
   },
   "source": [
    "# **Step 7 : Building the Web Interface**\n",
    "Why Gradio?\n",
    "\n",
    "*    Gradio provides a quick and easy way to create web interfaces for machine learning models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "0oDH_0BBCz-Y",
    "outputId": "a1cd4231-7c3d-4313-8876-d2b636fd7cb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://a6543e47de1fefc0c0.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a6543e47de1fefc0c0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradio UI\n",
    "gr.Interface(\n",
    "    fn=generate_image,\n",
    "    inputs=gr.Textbox(\n",
    "        label=\"📝 Enter your image prompt\",\n",
    "        placeholder=\"e.g. A surreal landscape with floating islands\"\n",
    "    ),\n",
    "    outputs=gr.Image(type=\"pil\", label=\"🖼️ Generated Image\"),\n",
    "    title=\"🎨 Text-to-Image Generator (Stable Diffusion)\",\n",
    "    description=\"Enter a creative prompt to generate AI images using Stable Diffusion!\",\n",
    "    theme=\"default\"\n",
    ").launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HO2HVZvVGgBl"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUVqS85cHnF9"
   },
   "source": [
    "\n",
    "\n",
    "## **Possible Challenges we Have Faced**\n",
    "\n",
    "### 1. **Environment and Dependency Issues**\n",
    "\n",
    "* Installing heavy libraries like `diffusers`, `transformers`, `torch`, `safetensors`take time and cause version conflicts.\n",
    "* Frequent updates of Hugging Face libraries break compatibility.\n",
    "* CUDA compatibility issues during PyTorch or Stable Diffusion usage (e.g., wrong `torch_dtype` or incompatible CUDA versions).\n",
    "* Long installation times or memory overflows due to Colab RAM/VRAM limitations.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Hugging Face Authentication Problems**\n",
    "\n",
    "* Token errors due to:\n",
    "\n",
    "  * Expired token\n",
    "  * Wrong token scope (read vs write)\n",
    "  * Using `login()` in the wrong order or without internet access\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Model Loading Errors**\n",
    "\n",
    "* Issues with `StableDiffusionPipeline`:\n",
    "\n",
    "  * `use_safetensors=True` but the model doesn’t support it\n",
    "  * `torch_dtype=torch.float16` not supported on CPU\n",
    "  * Colab free tier  not have GPU available, which can cause the pipeline to crash or be slow\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Image Generation Failures**\n",
    "\n",
    "* Prompt too long or too short causing `pipe(prompt).images[0]` to fail\n",
    "* Timeout due to GPU overload or slow Hugging Face response\n",
    "* Output not returned as expected — resulting in corrupted or blank images\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Debugging and Exception Handling**\n",
    "\n",
    "* Lack of detailed error messages makes debugging harder\n",
    "* Your `try/except` block is good, but adding full tracebacks could improve diagnostics\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Gradio Deployment Challenges**\n",
    "\n",
    "* Internet issues during `demo.launch(share=True)` can cause interface failures\n",
    "* Gradio UI may lag in Colab environments\n",
    "* Colab runtime disconnects or times out frequently\n",
    "* Deploying to Hugging Face Spaces requires additional setup: GitHub integration, model card, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Hardware Limitations (Colab)**\n",
    "\n",
    "* Free GPU quota exceeded message\n",
    "* Out-of-memory error during image generation with high-resolution prompts\n",
    "* Colab shuts down runtime due to inactivity if testing takes too long\n",
    "\n",
    "---\n",
    "\n",
    "### 8. **Performance and Usability Gaps**\n",
    "\n",
    "* No visual feedback (like a progress bar) during image generation\n",
    "* No input validation — blank or broken prompt may crash the pipeline\n",
    "* Output image display lacks metadata, download options, or customization\n",
    "\n",
    "---\n",
    "\n",
    "### 9. **Security and Safety Concerns**\n",
    "\n",
    "* Hardcoded Hugging Face access token is visible in your notebook — this is a security vulnerability\n",
    "* The app allows open-ended text input, which could be misused for inappropriate prompt generation\n",
    "* If `safety_checker=None` is used, NSFW content may be generated\n",
    "\n",
    "---\n",
    "\n",
    "### 10. **Missing Functional Enhancements**\n",
    "\n",
    "* No prompt history or way to store previously generated images\n",
    "* No control over resolution, number of images, or visual style\n",
    "* No download/save option for the generated image\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SVzm3_9cPqb"
   },
   "source": [
    "Thank you!!!!!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
